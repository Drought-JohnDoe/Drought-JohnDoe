{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy.signal import detrend\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import regionmask\n",
    "from scipy.stats import zscore\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from joblib import Parallel, delayed\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_non_nan_2d_array(ds):\n",
    "# Check for valid time dimension\n",
    "    if 'time' in ds.dims:\n",
    "        time_len = len(ds.time.values)\n",
    "    elif 'year' in ds.dims:  # Fallback to 'year' if 'time' is not available\n",
    "        time_len = len(ds.year.values)\n",
    "    else:\n",
    "        raise ValueError(\"No valid time dimension found.\")\n",
    "    # Extract the dimensions for lat and lon\n",
    "    lat_len = ds.sizes['lat']\n",
    "    lon_len = ds.sizes['lon']\n",
    "    \n",
    "    # Reshape the data into a 2D array (time x space)\n",
    "    scpdsi_2d = ds.values.reshape(time_len, lat_len * lon_len)\n",
    "    \n",
    "    # Identify columns that are not entirely NaN\n",
    "    non_nan_mask = ~np.isnan(scpdsi_2d).any(axis=0)\n",
    "    non_nan_mask[16719] =0  # these two numbers are where event series has all nan and they have to be removed manuallly\n",
    "    non_nan_mask[137448] =0\n",
    "    # Apply the mask to filter out columns with all NaN values\n",
    "    scpdsi_non_nan = scpdsi_2d[:, non_nan_mask]\n",
    "    \n",
    "    return scpdsi_non_nan, non_nan_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"scPDSI.cru_ts4.06early1.1901.2021.cal_1950_21.bams.2022.GLOBAL.IGBP.WHC.1901.2021.nc\"\n",
    "scpdsi_nc = xr.open_dataset(filepath).sel(time = slice(\"1901\",\"2021\")).scpdsi.rename({\"latitude\":\"lat\",\"longitude\":\"lon\"})\n",
    "scpdsi_nc = scpdsi_nc.sel(time = slice(\"1901\",\"2020\"))\n",
    "ds,mask = convert_to_non_nan_2d_array(scpdsi_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = scpdsi_nc.lat.values\n",
    "lon = scpdsi_nc.lon.values\n",
    "coords = np.array(list(itertools.product(lon,lat)))\n",
    "coords_valid = coords[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_evt_series(array):\n",
    "    b = array\n",
    "    b = b.transpose(1,0)\n",
    "    b = b[~np.isnan(b).all(axis=1)]\n",
    "    b = np.less(b,-2)\n",
    "    b1 = b[:,:1].astype(int)\n",
    "    c = np.diff(b.astype(int))\n",
    "    d = np.append(b1,c,axis=1)\n",
    "    e = np.where(d == 1, 1, 0)\n",
    "    e = e.astype(bool)\n",
    "    f = np.arange(1, e.shape[1] + 1)\n",
    "    g = np.where(e, f, False)\n",
    "    # converting values to index\n",
    "    non_zero_mask = (g != 0)\n",
    "    result_series = np.where(non_zero_mask,g,np.nan)\n",
    "    event_series = np.sort(result_series)\n",
    "    return event_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59721, 1440)\n",
      "(59721, 1440)\n"
     ]
    }
   ],
   "source": [
    "evt_final = create_evt_series(ds)\n",
    "print(evt_final.shape)\n",
    "evt_final = evt_final[~np.isnan(evt_final).all(axis=1),:]\n",
    "print(evt_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Construction for time period 1901-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preproceesing for creating event series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=56)]: Using backend LokyBackend with 56 concurrent workers.\n",
      "[Parallel(n_jobs=56)]: Done  12 out of  61 | elapsed:   14.7s remaining:  1.0min\n",
      "[Parallel(n_jobs=56)]: Done  61 out of  61 | elapsed:   17.1s finished\n"
     ]
    }
   ],
   "source": [
    "start_years_list = np.arange(1901,1962)\n",
    "window_size = 60\n",
    "def evt_series(start_year):\n",
    "    new_dir = \"/Event_series\"\n",
    "    end_year = start_year+window_size\n",
    "    scpdsi_slice = scpdsi_nc.sel(time = (scpdsi_nc['time.year'] >=start_year) & (scpdsi_nc['time.year']<end_year))\n",
    "    ds,_ = convert_to_non_nan_2d_array(scpdsi_slice)\n",
    "    event_series = create_evt_series(ds)\n",
    "    np.save(os.path.join(new_dir,f\"event_series{start_year}.npy\"), event_series)\n",
    "with Parallel(n_jobs= 56,verbose = 1) as parallel:\n",
    "    parallel(delayed(evt_series)(start_year) for start_year in start_years_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "filepaths = glob.glob(\"/Event_series\" +  '/' + '*npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def tryint(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except ValueError:\n",
    "        return s\n",
    "    \n",
    "def alphanum_key(s):\n",
    "    \"\"\" Turn a string into a list of string and number chunks.\n",
    "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
    "    \"\"\"\n",
    "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "\n",
    "def sort_nicely(l):\n",
    "    \"\"\" Sort the given list in the way that humans expect.\n",
    "    \"\"\"\n",
    "    l.sort(key=alphanum_key)\n",
    "    sort_nicely(filepaths)\n",
    "filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import time\n",
    "from numba import jit\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "years = np.arange(1901,1962)\n",
    "for i, file in enumerate(filepaths):\n",
    "\n",
    "    events_load_path =  file\n",
    "    number_chunks = 100000\n",
    "\n",
    "    events_numpy = np.load(events_load_path)\n",
    "    print(events_numpy.shape)\n",
    "\n",
    "    # events_indices = np.load(\"All_Indices.npy\")\n",
    "    num_events = events_numpy.shape[0]\n",
    "    num_pairs = num_events**2\n",
    "    print(num_pairs)\n",
    "\n",
    "    # Suppose num_pairs is square matrix, find number  of elements in upper triangle\n",
    "    num_pairs_upper = int(num_pairs/2 + num_events/2) - num_events\n",
    "    print(num_pairs_upper)\n",
    "\n",
    "    # Get indices of upper triangle excluding diagonal\n",
    "    events_indices = np.array(np.triu_indices(num_events, k=1)).reshape(2, -1).T\n",
    "    print(events_indices.shape)\n",
    "\n",
    "    @jit(nopython=True, nogil = True)\n",
    "    def get_c_ij(ti, tj):\n",
    "        ti = ti[~np.isnan(ti)]\n",
    "        tj = tj[~np.isnan(tj)]\n",
    "        si = len(ti)\n",
    "        sj = len(tj)\n",
    "        Cij = 0\n",
    "        for l in range(0, si):\n",
    "            tl_i = ti[l]\n",
    "            time_diff = ti[l + 1] - tl_i if l < si - 1 else np.nan\n",
    "            time_diff2 = tl_i - ti[l - 1] if l > 0 else np.nan\n",
    "            for m in range(0, sj):\n",
    "                tm_j = tj[m]\n",
    "                time_diff3 = tj[m + 1] - tm_j if m < sj - 1 else np.nan\n",
    "                time_diff4 = tm_j - tj[m - 1] if m > 0 else np.nan\n",
    "\n",
    "                # t = np.abs(tl_i - tm_j)\n",
    "                t = tl_i - tm_j\n",
    "\n",
    "                time_lag = min(time_diff, time_diff2, time_diff3, time_diff4) / 2\n",
    "                time_lag = time_lag if not np.isnan(time_lag) else 0\n",
    "\n",
    "                if (0 < t) & (t < time_lag) & (time_lag <= 3):\n",
    "                    j = 1\n",
    "                elif t == 0:\n",
    "                    j = 0.5\n",
    "                else:\n",
    "                    j = 0\n",
    "                Cij += j\n",
    "        return Cij\n",
    "\n",
    "    @jit(nopython=True, nogil = True)\n",
    "    def get_Q_ij(x, y):\n",
    "        x = x[~np.isnan(x)]\n",
    "        y = y[~np.isnan(y)]\n",
    "        Si = len(x)\n",
    "        Sj = len(y)\n",
    "        if Si == 0 or Sj == 0:\n",
    "            Qij = 0\n",
    "        else:\n",
    "            Qij = (get_c_ij(x, y) + get_c_ij(y, x)) / np.sqrt(Si * Sj)\n",
    "        return Qij\n",
    "\n",
    "    chunk_start_indices = np.linspace(0, events_indices.shape[0], number_chunks + 1).astype(int)\n",
    "\n",
    "    # Number of events in each chunk\n",
    "    chunk_size = chunk_start_indices[1] - chunk_start_indices[0]\n",
    "    print(chunk_size)\n",
    "\n",
    "    def get_Q_ij_chunk(events, start_idx, end_idx, events_indices):\n",
    "        Q = [get_Q_ij(events[i, :], events[j, :]) for i,j in events_indices[start_idx:end_idx]]\n",
    "        return Q\n",
    "\n",
    "    start_time = time.time()\n",
    "    with Parallel(n_jobs=48, verbose=1) as parallel:\n",
    "        temp = parallel(delayed(get_Q_ij_chunk)(events_numpy, chunk_start_indices[idx], chunk_start_indices[idx + 1], events_indices) for idx in range(len(chunk_start_indices) - 1))\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Time taken: {} mins {} secs\".format(int((end_time - start_time)/60), int((end_time - start_time)%60)))\n",
    "\n",
    "    print(\"Saving results...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Flatten list of lists\n",
    "    temp = list(itertools.chain(*temp))\n",
    "\n",
    "    # Convert list to numpy array\n",
    "    temp = np.array(temp)\n",
    "\n",
    "    # Use events_indices to put values in upper triangle\n",
    "    Q = np.zeros((num_events, num_events))\n",
    "    Q[events_indices[:, 0], events_indices[:, 1]] = temp\n",
    "    Q = Q + Q.T\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Time taken: {} mins {} secs\".format(int((end_time - start_time)/60), int((end_time - start_time)%60)))\n",
    "\n",
    "    # Save Q\n",
    "    Q_save_path = \"Qij_matrix\"\n",
    "    Q_save_filename = os.path.join(Q_save_path, f\"Q_{years[i]}.npy\")\n",
    "    start_time = time.time()\n",
    "    np.save(Q_save_filename, Q)\n",
    "    end_time = time.time()\n",
    "    print(\"Time taken: {} mins {} secs\".format(int((end_time - start_time)/60), int((end_time - start_time)%60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Calulation Matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_chunks = 100000\n",
    "\n",
    "events_numpy =  coords_valid\n",
    "print(events_numpy.shape)\n",
    "\n",
    "num_events = events_numpy.shape[0]\n",
    "num_pairs = num_events**2\n",
    "print(num_pairs)\n",
    "\n",
    "num_pairs_upper = int(num_pairs/2 + num_events/2) - num_events\n",
    "print(num_pairs_upper)\n",
    "\n",
    "# Get indices of upper triangle excluding diagonal\n",
    "events_indices = np.array(np.triu_indices(num_events, k=1)).reshape(2, -1).T\n",
    "print(events_indices.shape)\n",
    "\n",
    "@jit(nopython=True,nogil = True)\n",
    "def haversine(l1, l2):\n",
    "    lat1, lon1 = l1\n",
    "    lat2, lon2 = l2\n",
    "    lat1 = math.radians(lat1)\n",
    "    lon1 = math.radians(lon1)\n",
    "    lat2 = math.radians(lat2)\n",
    "    lon2 = math.radians(lon2)\n",
    "    earth_radius = 6371.0\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    phi = (lat1+lat2)/2\n",
    "    distance = earth_radius * math.sqrt((dlat**2) + (math.cos(phi)*dlon)**2)\n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "chunk_start_indices = np.linspace(0, events_indices.shape[0], number_chunks + 1).astype(int)\n",
    "\n",
    "chunk_size = chunk_start_indices[1] - chunk_start_indices[0]\n",
    "print(chunk_size)\n",
    "\n",
    "def get_Q_ij_chunk(events, start_idx, end_idx, events_indices):\n",
    "    Q = [haversine(events[i, :], events[j, :]) for i,j in events_indices[start_idx:end_idx]]\n",
    "    return Q\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "with Parallel(n_jobs=48, verbose=1) as parallel:\n",
    "    temp = parallel(delayed(get_Q_ij_chunk)(events_numpy, chunk_start_indices[idx], chunk_start_indices[idx + 1], events_indices) for idx in range(len(chunk_start_indices) - 1))\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "#  Flatten list of lists\n",
    "temp = list(itertools.chain(*temp))\n",
    "\n",
    "# Convert list to numpy array\n",
    "temp = np.array(temp)\n",
    "\n",
    "# Use events_indices to put values in upper triangle\n",
    "D= np.zeros((num_events, num_events))\n",
    "D[events_indices[:, 0], events_indices[:, 1]] = temp\n",
    "D = D +D.T\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken: {} mins {} secs\".format(int((end_time - start_time)/60), int((end_time - start_time)%60)))\n",
    "\n",
    "start_time = time.time()\n",
    "D_com = D.astype(np.float32)\n",
    "np.save(\"distance.npy\", D_com)\n",
    "end_time = time.time()\n",
    "print(\"Time taken: {} mins {} secs\".format(int((end_time - start_time)/60), int((end_time - start_time)%60)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
